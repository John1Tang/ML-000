{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stackingml_and_deepml.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNQYshf8C+qM8PIT+6pNa8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c9bdb0f57b04fd98e25dd70c81a88a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9f64e9de0c749a28477487380197877",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a4b24c4d7e5d43fab63efc62e8c27b2b",
              "IPY_MODEL_7e7a305a1a234fbf8cc07dec455f2593"
            ]
          }
        },
        "f9f64e9de0c749a28477487380197877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "a4b24c4d7e5d43fab63efc62e8c27b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d36deaf4b554431fab8b5393f00effc0",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82a9b6ab283a4ead9db1590963f83b37"
          }
        },
        "7e7a305a1a234fbf8cc07dec455f2593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_00d228ec68304841bbe40fe699c6118f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1e890f07dc0451481c2d22fc9440dd5"
          }
        },
        "d36deaf4b554431fab8b5393f00effc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82a9b6ab283a4ead9db1590963f83b37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00d228ec68304841bbe40fe699c6118f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1e890f07dc0451481c2d22fc9440dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "349e3641a4da4ea6863374abfa96fd1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb0fe59e88fd42bda33114afa777c11a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ae64ab221f949b08dceed0762420f8e",
              "IPY_MODEL_80b001e775f747c4947503aab577adff"
            ]
          }
        },
        "fb0fe59e88fd42bda33114afa777c11a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "7ae64ab221f949b08dceed0762420f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bbe98c61aaa847c3b49baccd93b40ee3",
            "_dom_classes": [],
            "description": "Epoch 0: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2345,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2345,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a84626de91704a6ca922ff46d6ad7076"
          }
        },
        "80b001e775f747c4947503aab577adff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac0234b033634c6dbd74c4a3c89572e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2345/2345 [01:25&lt;00:00, 27.40it/s, loss=0.521, v_num=2]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5dc880a500947179e8157a4c0d04144"
          }
        },
        "bbe98c61aaa847c3b49baccd93b40ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a84626de91704a6ca922ff46d6ad7076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac0234b033634c6dbd74c4a3c89572e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5dc880a500947179e8157a4c0d04144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7b4f504ecaf4c228d17ee0093774904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7459d1f27e84284bb6761848c4b380b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d8a372e459b4abba8adbdc98950d5d1",
              "IPY_MODEL_d2f1af74257d46ffabc00a618f03e379"
            ]
          }
        },
        "c7459d1f27e84284bb6761848c4b380b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "8d8a372e459b4abba8adbdc98950d5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_24409e24660a4b11b1aca3840f3b4fea",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 391,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 391,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4e88781788049f9bc0d090a87ed9929"
          }
        },
        "d2f1af74257d46ffabc00a618f03e379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c56e089f8eff43c8b1c7e23ad976b689",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 391/391 [00:06&lt;00:00, 61.55it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb6a3e164f5445fe9dcb0f1de516e647"
          }
        },
        "24409e24660a4b11b1aca3840f3b4fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4e88781788049f9bc0d090a87ed9929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c56e089f8eff43c8b1c7e23ad976b689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb6a3e164f5445fe9dcb0f1de516e647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2892e4da11844896a7ded830eac8fd52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6b7b7270ced546cea647c34880e6e551",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8cc14a61409b48f88942c69f5ec5247e",
              "IPY_MODEL_d4d3d0c75e8c47ab82acc7c530663d08"
            ]
          }
        },
        "6b7b7270ced546cea647c34880e6e551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "8cc14a61409b48f88942c69f5ec5247e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_80ae2b1fe742462eaaa5c3f281c796f8",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 391,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 391,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38a38572ce8641eeb612bd9a93a36996"
          }
        },
        "d4d3d0c75e8c47ab82acc7c530663d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c3a751e7eed494e9a4508a7d43b9952",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 391/391 [00:06&lt;00:00, 61.51it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_962d4eaf63764561b0b740d464e48aae"
          }
        },
        "80ae2b1fe742462eaaa5c3f281c796f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38a38572ce8641eeb612bd9a93a36996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c3a751e7eed494e9a4508a7d43b9952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "962d4eaf63764561b0b740d464e48aae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/John1Tang/ML-000/blob/main/Week16/stackingml_and_deepml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA9jxRT-6XcG"
      },
      "source": [
        "### Load data and data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3TkVcuRuWo2"
      },
      "source": [
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzV68swO6V1X",
        "outputId": "7ff5d949-94f9-4315-bba6-4d8981c490d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "seed = 42 # for the same data division\n",
        "\n",
        "kf = KFold(n_splits=5, random_state=seed,shuffle=True)\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/final/train_final.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/final/test_final.csv')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2EPTdMQDAUU"
      },
      "source": [
        "train_clean = df_train.copy()\n",
        "test_clean = df_test.copy()\n",
        "\n",
        "train_clean.fillna(0,inplace=True)\n",
        "test_clean.fillna(0,inplace=True)\n",
        "\n",
        "X_train = train_clean.drop(columns=['loan_status']).values\n",
        "Y_train = train_clean['loan_status'].values.astype(int)\n",
        "X_test = test_clean.drop(columns=['loan_status']).values\n",
        "Y_test = test_clean['loan_status'].values.astype(int)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVhCy21e89Bu"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "ss = MinMaxScaler()\n",
        "ss.fit(X_train)\n",
        "train_x_std = ss.transform(X_train)\n",
        "ss2 = MinMaxScaler()\n",
        "ss2.fit(X_test)\n",
        "test_x_std = ss2.transform(X_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de3P6cjQRDsm",
        "outputId": "7e760e6d-bced-4eca-fe0c-d02a2aadcbef"
      },
      "source": [
        "train_x_std.tolist()[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0061111111111111106,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.005915915915915916,\n",
              " 0.0,\n",
              " 0.08064516129032251,\n",
              " 0.08108108108108114,\n",
              " 0.07647058823529412,\n",
              " 0.07782672540381791,\n",
              " 0.2,\n",
              " 0.08079767742128084,\n",
              " 0.36628643852978454,\n",
              " 0.6635294117647058,\n",
              " 0.6627218934911243,\n",
              " 0.07647058823529412,\n",
              " 0.19736842105263158,\n",
              " 0.19736842105263158,\n",
              " 0.0,\n",
              " 0.09090909090909091,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jUly6Gf66x8",
        "outputId": "f7a38357-34ff-4f39-a7f1-e4f2b14785f2"
      },
      "source": [
        "X_train.shape, Y_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 145), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlJDmTVp689L"
      },
      "source": [
        "# split data for five fold\n",
        "\n",
        "five_fold_data = []\n",
        "\n",
        "for train_index, eval_index in kf.split(X_train):\n",
        "  x_train, x_eval = X_train[train_index], X_train[eval_index]\n",
        "  y_train, y_eval = Y_train[train_index], Y_train[eval_index]\n",
        "  \n",
        "  five_fold_data.append([(x_train, y_train), (x_eval, y_eval)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU56UVup6NX3"
      },
      "source": [
        "### EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "u8QrtXao6RzR",
        "outputId": "aebc903e-a54d-4d59-ed6f-14952dd368f1"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>continuous_annual_inc</th>\n",
              "      <th>continuous_annual_inc_joint</th>\n",
              "      <th>continuous_delinq_2yrs</th>\n",
              "      <th>continuous_dti</th>\n",
              "      <th>continuous_dti_joint</th>\n",
              "      <th>continuous_fico_range_high</th>\n",
              "      <th>continuous_fico_range_low</th>\n",
              "      <th>continuous_funded_amnt</th>\n",
              "      <th>continuous_funded_amnt_inv</th>\n",
              "      <th>continuous_inq_last_6mths</th>\n",
              "      <th>continuous_installment</th>\n",
              "      <th>continuous_int_rate</th>\n",
              "      <th>continuous_last_fico_range_high</th>\n",
              "      <th>continuous_last_fico_range_low</th>\n",
              "      <th>continuous_loan_amnt</th>\n",
              "      <th>loan_status</th>\n",
              "      <th>continuous_mths_since_last_delinq</th>\n",
              "      <th>continuous_mths_since_last_major_derog</th>\n",
              "      <th>continuous_mths_since_last_record</th>\n",
              "      <th>continuous_open_acc</th>\n",
              "      <th>continuous_pub_rec</th>\n",
              "      <th>discrete_addr_state_1_one_hot</th>\n",
              "      <th>discrete_addr_state_2_one_hot</th>\n",
              "      <th>discrete_addr_state_3_one_hot</th>\n",
              "      <th>discrete_addr_state_4_one_hot</th>\n",
              "      <th>discrete_addr_state_5_one_hot</th>\n",
              "      <th>discrete_addr_state_6_one_hot</th>\n",
              "      <th>discrete_addr_state_7_one_hot</th>\n",
              "      <th>discrete_addr_state_8_one_hot</th>\n",
              "      <th>discrete_addr_state_9_one_hot</th>\n",
              "      <th>discrete_addr_state_10_one_hot</th>\n",
              "      <th>discrete_addr_state_11_one_hot</th>\n",
              "      <th>discrete_addr_state_12_one_hot</th>\n",
              "      <th>discrete_addr_state_13_one_hot</th>\n",
              "      <th>discrete_addr_state_14_one_hot</th>\n",
              "      <th>discrete_addr_state_15_one_hot</th>\n",
              "      <th>discrete_addr_state_16_one_hot</th>\n",
              "      <th>discrete_addr_state_17_one_hot</th>\n",
              "      <th>discrete_addr_state_18_one_hot</th>\n",
              "      <th>discrete_addr_state_19_one_hot</th>\n",
              "      <th>...</th>\n",
              "      <th>discrete_purpose_11_one_hot</th>\n",
              "      <th>discrete_purpose_12_one_hot</th>\n",
              "      <th>discrete_pymnt_plan_1_one_hot</th>\n",
              "      <th>discrete_sub_grade_1_one_hot</th>\n",
              "      <th>discrete_sub_grade_2_one_hot</th>\n",
              "      <th>discrete_sub_grade_3_one_hot</th>\n",
              "      <th>discrete_sub_grade_4_one_hot</th>\n",
              "      <th>discrete_sub_grade_5_one_hot</th>\n",
              "      <th>discrete_sub_grade_6_one_hot</th>\n",
              "      <th>discrete_sub_grade_7_one_hot</th>\n",
              "      <th>discrete_sub_grade_8_one_hot</th>\n",
              "      <th>discrete_sub_grade_9_one_hot</th>\n",
              "      <th>discrete_sub_grade_10_one_hot</th>\n",
              "      <th>discrete_sub_grade_11_one_hot</th>\n",
              "      <th>discrete_sub_grade_12_one_hot</th>\n",
              "      <th>discrete_sub_grade_13_one_hot</th>\n",
              "      <th>discrete_sub_grade_14_one_hot</th>\n",
              "      <th>discrete_sub_grade_15_one_hot</th>\n",
              "      <th>discrete_sub_grade_16_one_hot</th>\n",
              "      <th>discrete_sub_grade_17_one_hot</th>\n",
              "      <th>discrete_sub_grade_18_one_hot</th>\n",
              "      <th>discrete_sub_grade_19_one_hot</th>\n",
              "      <th>discrete_sub_grade_20_one_hot</th>\n",
              "      <th>discrete_sub_grade_21_one_hot</th>\n",
              "      <th>discrete_sub_grade_22_one_hot</th>\n",
              "      <th>discrete_sub_grade_23_one_hot</th>\n",
              "      <th>discrete_sub_grade_24_one_hot</th>\n",
              "      <th>discrete_sub_grade_25_one_hot</th>\n",
              "      <th>discrete_sub_grade_26_one_hot</th>\n",
              "      <th>discrete_sub_grade_27_one_hot</th>\n",
              "      <th>discrete_sub_grade_28_one_hot</th>\n",
              "      <th>discrete_sub_grade_29_one_hot</th>\n",
              "      <th>discrete_sub_grade_30_one_hot</th>\n",
              "      <th>discrete_sub_grade_31_one_hot</th>\n",
              "      <th>discrete_sub_grade_32_one_hot</th>\n",
              "      <th>discrete_sub_grade_33_one_hot</th>\n",
              "      <th>discrete_sub_grade_34_one_hot</th>\n",
              "      <th>discrete_sub_grade_35_one_hot</th>\n",
              "      <th>discrete_term_1_one_hot</th>\n",
              "      <th>discrete_term_2_one_hot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.91</td>\n",
              "      <td>NaN</td>\n",
              "      <td>679.0</td>\n",
              "      <td>675.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>123.03</td>\n",
              "      <td>13.99</td>\n",
              "      <td>564.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>65000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>719.0</td>\n",
              "      <td>715.0</td>\n",
              "      <td>24700.0</td>\n",
              "      <td>24700.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>820.28</td>\n",
              "      <td>11.99</td>\n",
              "      <td>699.0</td>\n",
              "      <td>695.0</td>\n",
              "      <td>24700.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63000.0</td>\n",
              "      <td>71000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.78</td>\n",
              "      <td>13.85</td>\n",
              "      <td>699.0</td>\n",
              "      <td>695.0</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>432.66</td>\n",
              "      <td>10.78</td>\n",
              "      <td>704.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>104433.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>699.0</td>\n",
              "      <td>695.0</td>\n",
              "      <td>10400.0</td>\n",
              "      <td>10400.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>289.91</td>\n",
              "      <td>22.45</td>\n",
              "      <td>704.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>10400.0</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>694.0</td>\n",
              "      <td>690.0</td>\n",
              "      <td>11950.0</td>\n",
              "      <td>11950.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>405.18</td>\n",
              "      <td>13.44</td>\n",
              "      <td>759.0</td>\n",
              "      <td>755.0</td>\n",
              "      <td>11950.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 146 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   continuous_annual_inc  ...  discrete_term_2_one_hot\n",
              "0                55000.0  ...                        0\n",
              "1                65000.0  ...                        0\n",
              "2                63000.0  ...                        1\n",
              "3               104433.0  ...                        1\n",
              "4                34000.0  ...                        0\n",
              "\n",
              "[5 rows x 146 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMaYoK7Q-aH-",
        "outputId": "c30ca5ee-b2f7-4475-ad33-eba9a47995ed"
      },
      "source": [
        "df_train.columns.tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['continuous_annual_inc',\n",
              " 'continuous_annual_inc_joint',\n",
              " 'continuous_delinq_2yrs',\n",
              " 'continuous_dti',\n",
              " 'continuous_dti_joint',\n",
              " 'continuous_fico_range_high',\n",
              " 'continuous_fico_range_low',\n",
              " 'continuous_funded_amnt',\n",
              " 'continuous_funded_amnt_inv',\n",
              " 'continuous_inq_last_6mths',\n",
              " 'continuous_installment',\n",
              " 'continuous_int_rate',\n",
              " 'continuous_last_fico_range_high',\n",
              " 'continuous_last_fico_range_low',\n",
              " 'continuous_loan_amnt',\n",
              " 'loan_status',\n",
              " 'continuous_mths_since_last_delinq',\n",
              " 'continuous_mths_since_last_major_derog',\n",
              " 'continuous_mths_since_last_record',\n",
              " 'continuous_open_acc',\n",
              " 'continuous_pub_rec',\n",
              " 'discrete_addr_state_1_one_hot',\n",
              " 'discrete_addr_state_2_one_hot',\n",
              " 'discrete_addr_state_3_one_hot',\n",
              " 'discrete_addr_state_4_one_hot',\n",
              " 'discrete_addr_state_5_one_hot',\n",
              " 'discrete_addr_state_6_one_hot',\n",
              " 'discrete_addr_state_7_one_hot',\n",
              " 'discrete_addr_state_8_one_hot',\n",
              " 'discrete_addr_state_9_one_hot',\n",
              " 'discrete_addr_state_10_one_hot',\n",
              " 'discrete_addr_state_11_one_hot',\n",
              " 'discrete_addr_state_12_one_hot',\n",
              " 'discrete_addr_state_13_one_hot',\n",
              " 'discrete_addr_state_14_one_hot',\n",
              " 'discrete_addr_state_15_one_hot',\n",
              " 'discrete_addr_state_16_one_hot',\n",
              " 'discrete_addr_state_17_one_hot',\n",
              " 'discrete_addr_state_18_one_hot',\n",
              " 'discrete_addr_state_19_one_hot',\n",
              " 'discrete_addr_state_20_one_hot',\n",
              " 'discrete_addr_state_21_one_hot',\n",
              " 'discrete_addr_state_22_one_hot',\n",
              " 'discrete_addr_state_23_one_hot',\n",
              " 'discrete_addr_state_24_one_hot',\n",
              " 'discrete_addr_state_25_one_hot',\n",
              " 'discrete_addr_state_26_one_hot',\n",
              " 'discrete_addr_state_27_one_hot',\n",
              " 'discrete_addr_state_28_one_hot',\n",
              " 'discrete_addr_state_29_one_hot',\n",
              " 'discrete_addr_state_30_one_hot',\n",
              " 'discrete_addr_state_31_one_hot',\n",
              " 'discrete_addr_state_32_one_hot',\n",
              " 'discrete_addr_state_33_one_hot',\n",
              " 'discrete_addr_state_34_one_hot',\n",
              " 'discrete_addr_state_35_one_hot',\n",
              " 'discrete_addr_state_36_one_hot',\n",
              " 'discrete_addr_state_37_one_hot',\n",
              " 'discrete_addr_state_38_one_hot',\n",
              " 'discrete_addr_state_39_one_hot',\n",
              " 'discrete_addr_state_40_one_hot',\n",
              " 'discrete_addr_state_41_one_hot',\n",
              " 'discrete_addr_state_42_one_hot',\n",
              " 'discrete_addr_state_43_one_hot',\n",
              " 'discrete_addr_state_44_one_hot',\n",
              " 'discrete_addr_state_45_one_hot',\n",
              " 'discrete_addr_state_46_one_hot',\n",
              " 'discrete_addr_state_47_one_hot',\n",
              " 'discrete_addr_state_48_one_hot',\n",
              " 'discrete_addr_state_49_one_hot',\n",
              " 'discrete_application_type_1_one_hot',\n",
              " 'discrete_application_type_2_one_hot',\n",
              " 'discrete_emp_length_1_one_hot',\n",
              " 'discrete_emp_length_2_one_hot',\n",
              " 'discrete_emp_length_3_one_hot',\n",
              " 'discrete_emp_length_4_one_hot',\n",
              " 'discrete_emp_length_5_one_hot',\n",
              " 'discrete_emp_length_6_one_hot',\n",
              " 'discrete_emp_length_7_one_hot',\n",
              " 'discrete_emp_length_8_one_hot',\n",
              " 'discrete_emp_length_9_one_hot',\n",
              " 'discrete_emp_length_10_one_hot',\n",
              " 'discrete_emp_length_11_one_hot',\n",
              " 'discrete_emp_length_12_one_hot',\n",
              " 'discrete_grade_1_one_hot',\n",
              " 'discrete_grade_2_one_hot',\n",
              " 'discrete_grade_3_one_hot',\n",
              " 'discrete_grade_4_one_hot',\n",
              " 'discrete_grade_5_one_hot',\n",
              " 'discrete_grade_6_one_hot',\n",
              " 'discrete_grade_7_one_hot',\n",
              " 'discrete_home_ownership_1_one_hot',\n",
              " 'discrete_home_ownership_2_one_hot',\n",
              " 'discrete_home_ownership_3_one_hot',\n",
              " 'discrete_home_ownership_4_one_hot',\n",
              " 'discrete_policy_code_1_one_hot',\n",
              " 'discrete_purpose_1_one_hot',\n",
              " 'discrete_purpose_2_one_hot',\n",
              " 'discrete_purpose_3_one_hot',\n",
              " 'discrete_purpose_4_one_hot',\n",
              " 'discrete_purpose_5_one_hot',\n",
              " 'discrete_purpose_6_one_hot',\n",
              " 'discrete_purpose_7_one_hot',\n",
              " 'discrete_purpose_8_one_hot',\n",
              " 'discrete_purpose_9_one_hot',\n",
              " 'discrete_purpose_10_one_hot',\n",
              " 'discrete_purpose_11_one_hot',\n",
              " 'discrete_purpose_12_one_hot',\n",
              " 'discrete_pymnt_plan_1_one_hot',\n",
              " 'discrete_sub_grade_1_one_hot',\n",
              " 'discrete_sub_grade_2_one_hot',\n",
              " 'discrete_sub_grade_3_one_hot',\n",
              " 'discrete_sub_grade_4_one_hot',\n",
              " 'discrete_sub_grade_5_one_hot',\n",
              " 'discrete_sub_grade_6_one_hot',\n",
              " 'discrete_sub_grade_7_one_hot',\n",
              " 'discrete_sub_grade_8_one_hot',\n",
              " 'discrete_sub_grade_9_one_hot',\n",
              " 'discrete_sub_grade_10_one_hot',\n",
              " 'discrete_sub_grade_11_one_hot',\n",
              " 'discrete_sub_grade_12_one_hot',\n",
              " 'discrete_sub_grade_13_one_hot',\n",
              " 'discrete_sub_grade_14_one_hot',\n",
              " 'discrete_sub_grade_15_one_hot',\n",
              " 'discrete_sub_grade_16_one_hot',\n",
              " 'discrete_sub_grade_17_one_hot',\n",
              " 'discrete_sub_grade_18_one_hot',\n",
              " 'discrete_sub_grade_19_one_hot',\n",
              " 'discrete_sub_grade_20_one_hot',\n",
              " 'discrete_sub_grade_21_one_hot',\n",
              " 'discrete_sub_grade_22_one_hot',\n",
              " 'discrete_sub_grade_23_one_hot',\n",
              " 'discrete_sub_grade_24_one_hot',\n",
              " 'discrete_sub_grade_25_one_hot',\n",
              " 'discrete_sub_grade_26_one_hot',\n",
              " 'discrete_sub_grade_27_one_hot',\n",
              " 'discrete_sub_grade_28_one_hot',\n",
              " 'discrete_sub_grade_29_one_hot',\n",
              " 'discrete_sub_grade_30_one_hot',\n",
              " 'discrete_sub_grade_31_one_hot',\n",
              " 'discrete_sub_grade_32_one_hot',\n",
              " 'discrete_sub_grade_33_one_hot',\n",
              " 'discrete_sub_grade_34_one_hot',\n",
              " 'discrete_sub_grade_35_one_hot',\n",
              " 'discrete_term_1_one_hot',\n",
              " 'discrete_term_2_one_hot']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLpUsIAe_vqp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR1aX0IsFIYj"
      },
      "source": [
        "## Integrate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR5TA0gwFMl3"
      },
      "source": [
        "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier)\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from lightgbm.sklearn import LGBMClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.model_selection import (GridSearchCV, KFold)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uUTXjiL9NyF",
        "outputId": "4e105fcc-4533-457a-aeb7-bc36815f115f"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
        "rnd_clf.fit(X_train,Y_train)\n",
        "rnd_clf.score(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQr6xFyLEI2s",
        "outputId": "5e30136e-bc25-4f7c-c9df-04e0ade27242"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_clf = SGDClassifier(random_state=20)\n",
        "sgd_clf.fit(X_train,Y_train)\n",
        "sgd_clf.score(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8639"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UujT_e3VER3z",
        "outputId": "ba53e4aa-4115-4ae6-d9bd-188f7164f418"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gdbt_clf = GradientBoostingClassifier(random_state = 20)\n",
        "gdbt_clf.fit(X_train,Y_train)\n",
        "gdbt_clf.score(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91772"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORhU3T7mEpqL",
        "outputId": "eeeda58c-9c2a-4bd5-ee55-f93510bbd5a7"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ada_clf = AdaBoostClassifier()\n",
        "ada_clf.fit(X_train,Y_train)\n",
        "ada_clf.score(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91604"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmOPIGy9EzkD",
        "outputId": "b39bc011-497d-4594-801b-40a7984ff372"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgbm_clf = LGBMClassifier()\n",
        "lgbm_clf.fit(X_train,Y_train)\n",
        "lgbm_clf.score(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHEMEx9aEONR",
        "outputId": "91b0cb3f-79da-4bf5-a3f4-664b731f2b71"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_clf = LogisticRegression(random_state = 20)\n",
        "lr_clf.fit(X_train,Y_train)\n",
        "lr_clf.score(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91108"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0NO6rWaE7uA",
        "outputId": "f0327d69-456a-4856-da4c-142a9a9bd6c3"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgb_clf = XGBClassifier()\n",
        "xgb_clf.fit(X_train,Y_train)\n",
        "xgb_clf.score(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91712"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTiBDQjs73_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fcc89c3-4044-4e51-dd54-1ddb54c23a20"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knc_clf = KNeighborsClassifier()\n",
        "knc_clf.fit(train_x_std,Y_train)\n",
        "knc_clf.score(test_x_std,Y_test)\n",
        "# knc_clf.fit(X_train,Y_train)\n",
        "# knc_clf.score(X_train,Y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHpW0D5V6Bu-"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "voting_clf = VotingClassifier(estimators=[('rf',rnd_clf ),('gdbt',gdbt_clf ),('ada',ada_clf ),('lgbm',lgbm_clf ),('xgb',xgb_clf )],\n",
        "                              voting='hard')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtDkuHJBF4eh",
        "outputId": "3a5418a7-ca9a-492d-8e8b-21a983ffb465"
      },
      "source": [
        "voting_clf.fit(X_train,Y_train)\n",
        "voting_clf.score(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91814"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c58_LafpmFiE"
      },
      "source": [
        "## Stacking Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L80-9dQjz7w8"
      },
      "source": [
        "X = train_x_std\n",
        "X_predict = test_x_std\n",
        "y = Y_train"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g4M_Hm--cER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5cf2a5-2af7-4752-e4ac-022eca99d273"
      },
      "source": [
        "X_predict.shape[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgysZbjF1UJ0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "n_folds = 5\n",
        "skf=StratifiedKFold(n_splits=n_folds,random_state=None)\n",
        "# X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.2, random_state=2020)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fldPfhySgyJC"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
        "\n",
        "clfs = [RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
        "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
        "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spLBxeB8RY3G"
      },
      "source": [
        "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))  \n",
        "dataset_blend_test = np.zeros((X_predict.shape[0], len(clfs)))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HerfcW93LE0"
      },
      "source": [
        "Layer 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmBsgot63DSA"
      },
      "source": [
        "for j, clf in enumerate(clfs):\n",
        "    # print(j, clf)\n",
        "    dataset_blend_test_j = np.zeros((X_predict.shape[0], len(clfs)))\n",
        "    for i, (train, test) in enumerate(skf.split(X_train, Y_train)):\n",
        "        # print(\"Fold\", i)\n",
        "        X_train_inner, y_train_inner, X_test_inner, y_test_inner = X[train], y[train], X[test], y[test]\n",
        "        clf.fit(X_train_inner, y_train_inner)\n",
        "        y_submission = clf.predict_proba(X_test_inner)[:, 1]\n",
        "        dataset_blend_train[test, j] = y_submission\n",
        "        dataset_blend_test_j[:, i] = clf.predict_proba(X_predict)[:, 1]\n",
        "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j4zR6U05gp7"
      },
      "source": [
        "Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDFPdnU75nYF"
      },
      "source": [
        "clf2 = LogisticRegression(C=0.1,max_iter=100)\n",
        "clf2.fit(dataset_blend_train, y)\n",
        "y_submission = clf2.predict_proba(dataset_blend_test)[:, 1]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGJTxMDhI3W7",
        "outputId": "0478f204-92c7-44a3-c15c-a6eceb09c84a"
      },
      "source": [
        "print(\"Linear stretch of predictions to [0,1]\")\n",
        "y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
        "print(\"blend result\")\n",
        "print(\"val auc Score: %f\" % (roc_auc_score(Y_test, y_submission)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear stretch of predictions to [0,1]\n",
            "blend result\n",
            "val auc Score: 0.955269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLwlLzkt93tF"
      },
      "source": [
        "## Deep Learning -- Tabnet & improve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyNu3jXMPTcw",
        "outputId": "f692e1e0-4358-4985-f350-616864b4bdcb"
      },
      "source": [
        "!pip install einops\n",
        "\n",
        "!pip install pytorch-lightning sklearn"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/b9/59ce5be6679884579c276f5f208587c3312e8323bd7ce27be278b7af98b3/pytorch_lightning-1.3.2-py3-none-any.whl (805kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Collecting fsspec[http]>=2021.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/52/816d1a3a599176057bf29dfacb1f8fadb61d35fbd96cb1bab4aaa7df83c0/fsspec-2021.5.0-py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 67.5MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e8/513cd9d0b1c83dc14cd8f788d05cd6a34758d4fd7e4f9e5ecd5d7d599c95/torchmetrics-0.3.2-py3-none-any.whl (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 72.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.8.1+cu101)\n",
            "Collecting pyDeprecate==0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/14/52/aa227a0884df71ed1957649085adf2b8bc2a1816d037c2f18b3078854516/pyDeprecate-0.3.0-py3-none-any.whl\n",
            "Collecting PyYAML<=5.4.1,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 72.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 69.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: requests; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=2021.4.0->pytorch-lightning) (2.23.0)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 61.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning) (2.4.7)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.32.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.3.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.36.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.30.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (56.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (2.10)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch-lightning) (21.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.2.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=217d8805d9ac046d038039bfa4c8b1e5b6b4c845e16b23b45b99e2cfd0142683\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built future\n",
            "Installing collected packages: async-timeout, multidict, yarl, aiohttp, fsspec, torchmetrics, pyDeprecate, PyYAML, future, pytorch-lightning\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.5.0 future-0.18.2 multidict-5.1.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.2 torchmetrics-0.3.2 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56YVb4_Xn21h",
        "outputId": "5f886c9b-d7da-4e1b-cc33-8a2f62751529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP0XEhvmlSWb"
      },
      "source": [
        "class EmbeddingFactory(nn.Module):\n",
        "    def __init__(self, x, dim_out):\n",
        "        super().__init__()\n",
        "        self.dim_out = dim_out\n",
        "        self.module_list = nn.ModuleList(\n",
        "            [nn.Embedding(len(set(np.unique(x[:, col]))), dim_out) for col in range(x.shape[1])])\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = [self.module_list[col](x[:, col]).unsqueeze(2) for col in range(x.shape[1])]\n",
        "        return torch.cat(result, dim=2)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FDeWcthgqqx"
      },
      "source": [
        "# coding = 'utf-8'\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "\n",
        "def encode_label(x):\n",
        "    unique=sorted(list(set([str(item) for item in np.unique(x)])))\n",
        "    kv = {unique[i]: i for i in range(len(unique))}\n",
        "    vfunc = np.vectorize(lambda x: kv[str(x)])\n",
        "    return vfunc(x)\n",
        "\n",
        "def encode_label_mat(x):\n",
        "    _, ncol = x.shape\n",
        "    result = np.empty_like(x, dtype=int)\n",
        "    for col in range(ncol):\n",
        "        result[:,col] = encode_label(x[:, col])\n",
        "    return result\n",
        "\n",
        "def discretize(x, nbins=20):\n",
        "    nrow, ncol = x.shape\n",
        "    result = np.empty_like(x)\n",
        "    interval_list = list()\n",
        "    for col in range(ncol):\n",
        "        intervals = sorted(list(set(get_quantile_interval(x[:, col], nbins))))\n",
        "        interval_centroid = list()\n",
        "\n",
        "        for i in range(len(intervals) - 1):\n",
        "            interval_centroid.append(0.5 * (intervals[i] + intervals[i + 1]))\n",
        "        func = np.vectorize(lambda x: get_interval_v2(x, intervals))\n",
        "        result[:, col] = encode_label(func(x[:, col]))\n",
        "        interval_list.append(interval_centroid)\n",
        "    return result.astype(np.int64), interval_list\n",
        "\n",
        "def get_quantile_interval(data, nbins):\n",
        "    quantiles = get_uniform_interval(0, 1, nbins)\n",
        "    return list(np.quantile(data[(~pd.isnull(data)) & (data != np.inf) & (data != -np.inf)], quantiles))\n",
        "\n",
        "def get_uniform_interval(minimum, maximum, nbins):\n",
        "    result = [minimum]\n",
        "    step_size = (float(maximum - minimum)) / nbins\n",
        "    for index in range(nbins - 1):\n",
        "        result.append(minimum + step_size * (index + 1))\n",
        "    result.append(maximum)\n",
        "    return result\n",
        "\n",
        "def get_interval_v2(x, sorted_intervals):\n",
        "    if pd.isnull(x):\n",
        "        return -1\n",
        "    if x == np.inf:\n",
        "        return -2\n",
        "    if x == -np.inf:\n",
        "        return -3\n",
        "    interval = 0\n",
        "    found = False\n",
        "    sorted_intervals.append(np.inf)\n",
        "    while not found and interval < len(sorted_intervals) - 1:\n",
        "        if sorted_intervals[interval] <= x < sorted_intervals[interval + 1]:\n",
        "            return interval\n",
        "        else:\n",
        "            interval += 1"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcH1GYHhgNW0"
      },
      "source": [
        "import torch\n",
        "x = np.concatenate([X_train, X_test])\n",
        "x_dis, centroids = discretize(x)\n",
        "x_dis_train = x_dis[:50000, :]\n",
        "x_dis_test = x_dis[50000:,:]"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPh0E4DKf4tS"
      },
      "source": [
        "from torch import nn\n",
        "from torch.autograd import Function\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "\n",
        "\"\"\"\n",
        "Other possible implementations:\n",
        "https://github.com/KrisKorrel/sparsemax-pytorch/blob/master/sparsemax.py\n",
        "https://github.com/msobroza/SparsemaxPytorch/blob/master/mnist/sparsemax.py\n",
        "https://github.com/vene/sparse-structured-attention/blob/master/pytorch/torchsparseattn/sparsemax.py\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# credits to Yandex https://github.com/Qwicen/node/blob/master/lib/nn_utils.py\n",
        "def _make_ix_like(input, dim=0):\n",
        "    d = input.size(dim)\n",
        "    rho = torch.arange(1, d + 1, device=input.device, dtype=input.dtype)\n",
        "    view = [1] * input.dim()\n",
        "    view[0] = -1\n",
        "    return rho.view(view).transpose(0, dim)\n",
        "\n",
        "\n",
        "class SparsemaxFunction(Function):\n",
        "    \"\"\"\n",
        "    An implementation of sparsemax (Martins & Astudillo, 2016). See\n",
        "    :cite:`DBLP:journals/corr/MartinsA16` for detailed description.\n",
        "    By Ben Peters and Vlad Niculae\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, dim=-1):\n",
        "        \"\"\"sparsemax: normalizing sparse transform (a la softmax)\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        ctx : torch.autograd.function._ContextMethodMixin\n",
        "        input : torch.Tensor\n",
        "            any shape\n",
        "        dim : int\n",
        "            dimension along which to apply sparsemax\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output : torch.Tensor\n",
        "            same shape as input\n",
        "\n",
        "        \"\"\"\n",
        "        ctx.dim = dim\n",
        "        max_val, _ = input.max(dim=dim, keepdim=True)\n",
        "        input -= max_val  # same numerical stability trick as for softmax\n",
        "        tau, supp_size = SparsemaxFunction._threshold_and_support(input, dim=dim)\n",
        "        output = torch.clamp(input - tau, min=0)\n",
        "        ctx.save_for_backward(supp_size, output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        supp_size, output = ctx.saved_tensors\n",
        "        dim = ctx.dim\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[output == 0] = 0\n",
        "\n",
        "        v_hat = (grad_input.sum(dim=dim) / supp_size).squeeze()\n",
        "        v_hat = v_hat.unsqueeze(dim)\n",
        "        grad_input = torch.where(output != 0, grad_input - v_hat, grad_input)\n",
        "        return grad_input, None\n",
        "\n",
        "    @staticmethod\n",
        "    def _threshold_and_support(input, dim=-1):\n",
        "        \"\"\"Sparsemax building block: compute the threshold\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input: torch.Tensor\n",
        "            any dimension\n",
        "        dim : int\n",
        "            dimension along which to apply the sparsemax\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tau : torch.Tensor\n",
        "            the threshold value\n",
        "        support_size : torch.Tensor\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        input_srt, _ = torch.sort(input, descending=True, dim=dim)\n",
        "        input_cumsum = input_srt.cumsum(dim) - 1\n",
        "        rhos = _make_ix_like(input, dim)\n",
        "        support = rhos * input_srt > input_cumsum\n",
        "\n",
        "        support_size = support.sum(dim=dim).unsqueeze(dim)\n",
        "        tau = input_cumsum.gather(dim, support_size - 1)\n",
        "        tau /= support_size.to(input.dtype)\n",
        "        return tau, support_size\n",
        "\n",
        "\n",
        "sparsemax = SparsemaxFunction.apply\n",
        "\n",
        "\n",
        "class Sparsemax(nn.Module):\n",
        "\n",
        "    def __init__(self, dim=-1):\n",
        "        self.dim = dim\n",
        "        super(Sparsemax, self).__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return sparsemax(input, self.dim)\n",
        "\n",
        "\n",
        "class Entmax15(nn.Module):\n",
        "    def __init__(self, dim=-1):\n",
        "        super().__init_()\n",
        "        self.dim=dim\n",
        "            \n",
        "    @staticmethod\n",
        "    def _threshold_and_support(input, dim=-1):\n",
        "        Xsrt, _ = torch.sort(input, descending=True, dim=dim)\n",
        "\n",
        "        rho = _make_ix_like(input, dim)\n",
        "        mean = Xsrt.cumsum(dim) / rho\n",
        "        mean_sq = (Xsrt ** 2).cumsum(dim) / rho\n",
        "        ss = rho * (mean_sq - mean ** 2)\n",
        "        delta = (1 - ss) / rho\n",
        "\n",
        "        delta_nz = torch.clamp(delta, 0)\n",
        "        tau = mean - torch.sqrt(delta_nz)\n",
        "\n",
        "        support_size = (tau <= Xsrt).sum(dim).unsqueeze(dim)\n",
        "        tau_star = tau.gather(dim, support_size - 1)\n",
        "        return tau_star, support_size\n",
        "    def forward(self, input):\n",
        "        max_val, _ = input.max(dim=self.dim, keepdim=True)\n",
        "        input = input - max_val  # same numerical stability trick as for softmax\n",
        "        input = input / 2  # divide by 2 to solve actual Entmax\n",
        "\n",
        "        tau_star, _ = Entmax15Function._threshold_and_support(input, self.dim)\n",
        "        output = torch.clamp(input - tau_star, min=0) ** 2\n",
        "        ctx.save_for_backward(output)\n",
        "        return output \n",
        "\n",
        "    def backward(self, output, grad):\n",
        "        Y = output\n",
        "        gppr = Y.sqrt()  # = 1 / g'' (Y)\n",
        "        dX = grad_output * gppr\n",
        "        q = dX.sum(ctx.dim) / gppr.sum(ctx.dim)\n",
        "        q = q.unsqueeze(ctx.dim)\n",
        "        dX -= q * gppr\n",
        "        return dX, None"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Ak-02PfwCr"
      },
      "source": [
        "\n",
        "import torch\n",
        "from torch.nn import Linear, BatchNorm1d, ReLU\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "def initialize_non_glu(module, input_dim, output_dim):\n",
        "    gain_value = np.sqrt((input_dim+output_dim)/np.sqrt(4*input_dim))\n",
        "    torch.nn.init.xavier_normal_(module.weight, gain=gain_value)\n",
        "    # torch.nn.init.zeros_(module.bias)\n",
        "    return\n",
        "\n",
        "\n",
        "def initialize_glu(module, input_dim, output_dim):\n",
        "    gain_value = np.sqrt((input_dim+output_dim)/np.sqrt(input_dim))\n",
        "    torch.nn.init.xavier_normal_(module.weight, gain=gain_value)\n",
        "    # torch.nn.init.zeros_(module.bias)\n",
        "    return\n",
        "\n",
        "\n",
        "class GBN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "        Ghost Batch Normalization\n",
        "        https://arxiv.org/abs/1705.08741\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, virtual_batch_size=128, momentum=0.01):\n",
        "        super(GBN, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.virtual_batch_size = virtual_batch_size\n",
        "        self.bn = BatchNorm1d(self.input_dim, momentum=momentum)\n",
        "\n",
        "    def forward(self, x):\n",
        "        chunks = x.chunk(int(np.ceil(x.shape[0] / self.virtual_batch_size)), 0)\n",
        "        res = [self.bn(x_) for x_ in chunks]\n",
        "\n",
        "        return torch.cat(res, dim=0)\n",
        "\n",
        "\n",
        "class TabNet(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim,\n",
        "                 n_d=64, n_a=64,\n",
        "                 n_steps=5, gamma=1.3,\n",
        "                 n_independent=2, n_shared=2, epsilon=1e-15,\n",
        "                 virtual_batch_size=128, momentum=0.02,\n",
        "                 mask_type=\"sparsemax\"):\n",
        "        \"\"\"\n",
        "        Defines main part of the TabNet network without the embedding layers.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_dim : int\n",
        "            Number of features\n",
        "        output_dim : int or list of int for multi task classification\n",
        "            Dimension of network output\n",
        "            examples : one for regression, 2 for binary classification etc...\n",
        "        n_d : int\n",
        "            Dimension of the prediction  layer (usually between 4 and 64)\n",
        "        n_a : int\n",
        "            Dimension of the attention  layer (usually between 4 and 64)\n",
        "        n_steps : int\n",
        "            Number of sucessive steps in the newtork (usually betwenn 3 and 10)\n",
        "        gamma : float\n",
        "            Float above 1, scaling factor for attention updates (usually betwenn 1.0 to 2.0)\n",
        "        n_independent : int\n",
        "            Number of independent GLU layer in each GLU block (default 2)\n",
        "        n_shared : int\n",
        "            Number of independent GLU layer in each GLU block (default 2)\n",
        "        epsilon : float\n",
        "            Avoid log(0), this should be kept very low\n",
        "        virtual_batch_size : int\n",
        "            Batch size for Ghost Batch Normalization\n",
        "        momentum : float\n",
        "            Float value between 0 and 1 which will be used for momentum in all batch norm\n",
        "        mask_type : str\n",
        "            Either \"sparsemax\" or \"entmax\" : this is the masking function to use\n",
        "        \"\"\"\n",
        "        super(TabNet, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.is_multi_task = isinstance(output_dim, list)\n",
        "        self.n_d = n_d\n",
        "        self.n_a = n_a\n",
        "        self.n_steps = n_steps\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.n_independent = n_independent\n",
        "        self.n_shared = n_shared\n",
        "        self.virtual_batch_size = virtual_batch_size\n",
        "        self.mask_type = mask_type\n",
        "        self.initial_bn = BatchNorm1d(self.input_dim, momentum=0.01)\n",
        "\n",
        "        if self.n_shared > 0:\n",
        "            shared_feat_transform = torch.nn.ModuleList()\n",
        "            for i in range(self.n_shared):\n",
        "                if i == 0:\n",
        "                    shared_feat_transform.append(Linear(self.input_dim,\n",
        "                                                        2*(n_d + n_a),\n",
        "                                                        bias=False))\n",
        "                else:\n",
        "                    shared_feat_transform.append(Linear(n_d + n_a, 2*(n_d + n_a), bias=False))\n",
        "\n",
        "        else:\n",
        "            shared_feat_transform = None\n",
        "\n",
        "        self.initial_splitter = FeatTransformer(self.input_dim, n_d+n_a, shared_feat_transform,\n",
        "                                                n_glu_independent=self.n_independent,\n",
        "                                                virtual_batch_size=self.virtual_batch_size,\n",
        "                                                momentum=momentum)\n",
        "\n",
        "        self.feat_transformers = torch.nn.ModuleList()\n",
        "        self.att_transformers = torch.nn.ModuleList()\n",
        "\n",
        "        for step in range(n_steps):\n",
        "            transformer = FeatTransformer(self.input_dim, n_d+n_a, shared_feat_transform,\n",
        "                                          n_glu_independent=self.n_independent,\n",
        "                                          virtual_batch_size=self.virtual_batch_size,\n",
        "                                          momentum=momentum)\n",
        "            attention = AttentiveTransformer(n_a, self.input_dim,\n",
        "                                             virtual_batch_size=self.virtual_batch_size,\n",
        "                                             momentum=momentum,\n",
        "                                             mask_type=self.mask_type)\n",
        "            self.feat_transformers.append(transformer)\n",
        "            self.att_transformers.append(attention)\n",
        "\n",
        "        if self.is_multi_task:\n",
        "            self.multi_task_mappings = torch.nn.ModuleList()\n",
        "            for task_dim in output_dim:\n",
        "                task_mapping = Linear(n_d, task_dim, bias=False)\n",
        "                initialize_non_glu(task_mapping, n_d, task_dim)\n",
        "                self.multi_task_mappings.append(task_mapping)\n",
        "        else:\n",
        "            self.final_mapping = Linear(n_d, output_dim, bias=False)\n",
        "            initialize_non_glu(self.final_mapping, n_d, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = 0\n",
        "        x = self.initial_bn(x)\n",
        "\n",
        "        prior = torch.ones(x.shape, device=x.device)\n",
        "        M_loss = 0\n",
        "        att = self.initial_splitter(x)[:, self.n_d:]\n",
        "\n",
        "        for step in range(self.n_steps):\n",
        "            M = self.att_transformers[step](prior, att)\n",
        "            M_loss += torch.mean(torch.sum(torch.mul(M, torch.log(M+self.epsilon)),\n",
        "                                           dim=1))\n",
        "            # update prior\n",
        "            prior = torch.mul(self.gamma - M, prior)\n",
        "            # output\n",
        "            masked_x = torch.mul(M, x)\n",
        "            out = self.feat_transformers[step](masked_x)\n",
        "            d = ReLU()(out[:, :self.n_d])\n",
        "            res = torch.add(res, d)\n",
        "            # update attention\n",
        "            att = out[:, self.n_d:]\n",
        "\n",
        "        M_loss /= self.n_steps\n",
        "\n",
        "        if self.is_multi_task:\n",
        "            # Result will be in list format\n",
        "            out = []\n",
        "            for task_mapping in self.multi_task_mappings:\n",
        "                out.append(task_mapping(res))\n",
        "        else:\n",
        "            out = self.final_mapping(res)\n",
        "        return out, M_loss\n",
        "\n",
        "    def forward_masks(self, x):\n",
        "        x = self.initial_bn(x)\n",
        "\n",
        "        prior = torch.ones(x.shape, device=x.device)\n",
        "        M_explain = torch.zeros(x.shape, device=x.device)\n",
        "        att = self.initial_splitter(x)[:, self.n_d:]\n",
        "        masks = {}\n",
        "\n",
        "        for step in range(self.n_steps):\n",
        "            M = self.att_transformers[step](prior, att)\n",
        "            masks[step] = M\n",
        "            # update prior\n",
        "            prior = torch.mul(self.gamma - M, prior)\n",
        "            # output\n",
        "            masked_x = torch.mul(M, x)\n",
        "            out = self.feat_transformers[step](masked_x)\n",
        "            d = ReLU()(out[:, :self.n_d])\n",
        "            # explain\n",
        "            step_importance = torch.sum(d, dim=1)\n",
        "            M_explain += torch.mul(M, step_importance.unsqueeze(dim=1))\n",
        "            # update attention\n",
        "            att = out[:, self.n_d:]\n",
        "\n",
        "        return M_explain, masks\n",
        "\n",
        "class AttentiveTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim,\n",
        "                 virtual_batch_size=128,\n",
        "                 momentum=0.02,\n",
        "                 mask_type=\"entmax\"):\n",
        "        \"\"\"\n",
        "        Initialize an attention transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_dim : int\n",
        "            Input size\n",
        "        output_dim : int\n",
        "            Outpu_size\n",
        "        virtual_batch_size : int\n",
        "            Batch size for Ghost Batch Normalization\n",
        "        momentum : float\n",
        "            Float value between 0 and 1 which will be used for momentum in batch norm\n",
        "        mask_type : str\n",
        "            Either \"sparsemax\" or \"entmax\" : this is the masking function to use\n",
        "        \"\"\"\n",
        "        super(AttentiveTransformer, self).__init__()\n",
        "        self.fc = Linear(input_dim, output_dim, bias=False)\n",
        "        initialize_non_glu(self.fc, input_dim, output_dim)\n",
        "        self.bn = GBN(output_dim, virtual_batch_size=virtual_batch_size,\n",
        "                      momentum=momentum)\n",
        "\n",
        "        if mask_type == \"sparsemax\":\n",
        "            # Sparsemax\n",
        "            self.selector = Sparsemax(dim=-1)\n",
        "        elif mask_type == \"entmax\":\n",
        "            # Entmax\n",
        "            self.selector = Entmax15(dim=-1)\n",
        "        else:\n",
        "            raise NotImplementedError(\"Please choose either sparsemax\" +\n",
        "                                      \"or entmax as masktype\")\n",
        "\n",
        "    def forward(self, priors, processed_feat):\n",
        "        x = self.fc(processed_feat)\n",
        "        x = self.bn(x)\n",
        "        x = torch.mul(x, priors)\n",
        "        x = self.selector(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class FeatTransformer(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, shared_layers, n_glu_independent,\n",
        "                 virtual_batch_size=128, momentum=0.02):\n",
        "        super(FeatTransformer, self).__init__()\n",
        "        \"\"\"\n",
        "        Initialize a feature transformer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_dim : int\n",
        "            Input size\n",
        "        output_dim : int\n",
        "            Outpu_size\n",
        "        shared_layers : torch.nn.ModuleList\n",
        "            The shared block that should be common to every step\n",
        "        n_glu_independant : int\n",
        "            Number of independent GLU layers\n",
        "        virtual_batch_size : int\n",
        "            Batch size for Ghost Batch Normalization within GLU block(s)\n",
        "        momentum : float\n",
        "            Float value between 0 and 1 which will be used for momentum in batch norm\n",
        "        \"\"\"\n",
        "\n",
        "        params = {\n",
        "            'n_glu': n_glu_independent,\n",
        "            'virtual_batch_size': virtual_batch_size,\n",
        "            'momentum': momentum\n",
        "        }\n",
        "\n",
        "        if shared_layers is None:\n",
        "            # no shared layers\n",
        "            self.shared = torch.nn.Identity()\n",
        "            is_first = True\n",
        "        else:\n",
        "            self.shared = GLU_Block(input_dim, output_dim,\n",
        "                                    first=True,\n",
        "                                    shared_layers=shared_layers,\n",
        "                                    n_glu=len(shared_layers),\n",
        "                                    virtual_batch_size=virtual_batch_size,\n",
        "                                    momentum=momentum)\n",
        "            is_first = False\n",
        "\n",
        "        if n_glu_independent == 0:\n",
        "            # no independent layers\n",
        "            self.specifics = torch.nn.Identity()\n",
        "        else:\n",
        "            spec_input_dim = input_dim if is_first else output_dim\n",
        "            self.specifics = GLU_Block(spec_input_dim, output_dim,\n",
        "                                       first=is_first,\n",
        "                                       **params)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.shared(x)\n",
        "        x = self.specifics(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GLU_Block(torch.nn.Module):\n",
        "    \"\"\"\n",
        "        Independant GLU block, specific to each step\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, n_glu=2, first=False, shared_layers=None,\n",
        "                 virtual_batch_size=128, momentum=0.02):\n",
        "        super(GLU_Block, self).__init__()\n",
        "        self.first = first\n",
        "        self.shared_layers = shared_layers\n",
        "        self.n_glu = n_glu\n",
        "        self.glu_layers = torch.nn.ModuleList()\n",
        "\n",
        "        params = {\n",
        "            'virtual_batch_size': virtual_batch_size,\n",
        "            'momentum': momentum\n",
        "        }\n",
        "\n",
        "        fc = shared_layers[0] if shared_layers else None\n",
        "        self.glu_layers.append(GLU_Layer(input_dim, output_dim,\n",
        "                                         fc=fc,\n",
        "                                         **params))\n",
        "        for glu_id in range(1, self.n_glu):\n",
        "            fc = shared_layers[glu_id] if shared_layers else None\n",
        "            self.glu_layers.append(GLU_Layer(output_dim, output_dim,\n",
        "                                             fc=fc,\n",
        "                                             **params))\n",
        "\n",
        "    def forward(self, x):\n",
        "        scale = math.sqrt(0.5)\n",
        "        if self.first:  # the first layer of the block has no scale multiplication\n",
        "            x = self.glu_layers[0](x)\n",
        "            layers_left = range(1, self.n_glu)\n",
        "        else:\n",
        "            layers_left = range(self.n_glu)\n",
        "\n",
        "        for glu_id in layers_left:\n",
        "            x = torch.add(x, self.glu_layers[glu_id](x))\n",
        "            x = x*scale\n",
        "        return x\n",
        "\n",
        "\n",
        "class GLU_Layer(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, fc=None,\n",
        "                 virtual_batch_size=128, momentum=0.02):\n",
        "        super(GLU_Layer, self).__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        if fc:\n",
        "            self.fc = fc\n",
        "        else:\n",
        "            self.fc = Linear(input_dim, 2*output_dim, bias=False)\n",
        "        initialize_glu(self.fc, input_dim, 2*output_dim)\n",
        "\n",
        "        self.bn = GBN(2*output_dim, virtual_batch_size=virtual_batch_size,\n",
        "                      momentum=momentum)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = self.bn(x)\n",
        "        out = torch.mul(x[:, :self.output_dim], torch.sigmoid(x[:, self.output_dim:]))\n",
        "        return out"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443,
          "referenced_widgets": [
            "6c9bdb0f57b04fd98e25dd70c81a88a8",
            "f9f64e9de0c749a28477487380197877",
            "a4b24c4d7e5d43fab63efc62e8c27b2b",
            "7e7a305a1a234fbf8cc07dec455f2593",
            "d36deaf4b554431fab8b5393f00effc0",
            "82a9b6ab283a4ead9db1590963f83b37",
            "00d228ec68304841bbe40fe699c6118f",
            "c1e890f07dc0451481c2d22fc9440dd5",
            "349e3641a4da4ea6863374abfa96fd1a",
            "fb0fe59e88fd42bda33114afa777c11a",
            "7ae64ab221f949b08dceed0762420f8e",
            "80b001e775f747c4947503aab577adff",
            "bbe98c61aaa847c3b49baccd93b40ee3",
            "a84626de91704a6ca922ff46d6ad7076",
            "ac0234b033634c6dbd74c4a3c89572e6",
            "f5dc880a500947179e8157a4c0d04144",
            "f7b4f504ecaf4c228d17ee0093774904",
            "c7459d1f27e84284bb6761848c4b380b",
            "8d8a372e459b4abba8adbdc98950d5d1",
            "d2f1af74257d46ffabc00a618f03e379",
            "24409e24660a4b11b1aca3840f3b4fea",
            "a4e88781788049f9bc0d090a87ed9929",
            "c56e089f8eff43c8b1c7e23ad976b689",
            "eb6a3e164f5445fe9dcb0f1de516e647",
            "2892e4da11844896a7ded830eac8fd52",
            "6b7b7270ced546cea647c34880e6e551",
            "8cc14a61409b48f88942c69f5ec5247e",
            "d4d3d0c75e8c47ab82acc7c530663d08",
            "80ae2b1fe742462eaaa5c3f281c796f8",
            "38a38572ce8641eeb612bd9a93a36996",
            "1c3a751e7eed494e9a4508a7d43b9952",
            "962d4eaf63764561b0b740d464e48aae"
          ]
        },
        "id": "ZtUC0sLOPiVi",
        "outputId": "7f0d90eb-8fbb-4bab-e89d-d062634a79fa"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.metrics import Accuracy\n",
        "from einops import rearrange, reduce, repeat\n",
        "\n",
        "class TabDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        super().__init__()\n",
        "        self.x = torch.from_numpy(x).type(torch.int64) \n",
        "        self.y = torch.from_numpy(y).type(torch.float32).squeeze() \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx, :], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "train_dataloader = DataLoader(TabDataset(x_dis_train, Y_train), batch_size = 32, num_workers=6)\n",
        "test_dataloader = DataLoader(TabDataset(x_dis_test, Y_test), batch_size = 128, num_workers=6)\n",
        "class TrainingModuleV2(pl.LightningModule):\n",
        "    def __init__(self, x, dim_emb, dim_out, penalty=1e-3, **kwargs):\n",
        "        super().__init__()\n",
        "        self.penalty = penalty\n",
        "        self.embedding = EmbeddingFactory(x, dim_emb)\n",
        "        self.backbone = TabNet(x.shape[1]*dim_emb, dim_out, **kwargs)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.loss = nn.BCELoss()\n",
        "        self.accuracy = Accuracy()\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        return self.backbone(x)\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x = self.embedding(x)\n",
        "        x = rearrange(x, 'b n e -> b (n e)')\n",
        "        x, _ = self.backbone(x)\n",
        "        x = self.sigmoid(x.squeeze())\n",
        "        loss = self.loss(x.squeeze(), y.type(torch.float32))\n",
        "        acc = self.accuracy(x.squeeze(), y.type(torch.int32))\n",
        "        self.log(\"Validation loss\", loss)\n",
        "        self.log(\"Validation acc\", acc)\n",
        "        return loss, acc\n",
        "        \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x = self.embedding(x)\n",
        "        x = rearrange(x, 'b n e -> b (n e)')\n",
        "        x, m_loss = self.backbone(x)\n",
        "        x = self.sigmoid(x.squeeze())\n",
        "        loss = self.loss(x, y.type(torch.float32)) - self.penalty*m_loss\n",
        "        acc = self.accuracy(x, y.type(torch.int32))\n",
        "        self.log(\"Training loss\", loss)\n",
        "        self.log(\"Training acc\", acc)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-3)\n",
        "        return optimizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "training_module = TrainingModuleV2(x_dis, 32, 1, n_steps=2, n_independent=4, n_shared=4,)\n",
        "trainer = pl.Trainer(max_epochs=1, gpus=1, progress_bar_refresh_rate=100, val_check_interval=0.5)\n",
        "trainer.fit(training_module, train_dataloader, test_dataloader)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type             | Params\n",
            "-----------------------------------------------\n",
            "0 | embedding | EmbeddingFactory | 16.6 K\n",
            "1 | backbone  | TabNet           | 2.3 M \n",
            "2 | sigmoid   | Sigmoid          | 0     \n",
            "3 | loss      | BCELoss          | 0     \n",
            "4 | accuracy  | Accuracy         | 0     \n",
            "-----------------------------------------------\n",
            "2.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.3 M     Total params\n",
            "9.320     Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c9bdb0f57b04fd98e25dd70c81a88a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "349e3641a4da4ea6863374abfa96fd1a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7b4f504ecaf4c228d17ee0093774904",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2892e4da11844896a7ded830eac8fd52",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uud0tE-ZndND"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}